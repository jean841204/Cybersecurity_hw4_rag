"""
Google Books RAG æ¨è–¦ç³»çµ±
ä½¿ç”¨å…è²»è³‡æºï¼šFAISS + HuggingFace/Gemini
"""

import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import os
from dotenv import load_dotenv

load_dotenv()

# ==================== é…ç½®é¸é … ====================

# é¸æ“‡ä½¿ç”¨å“ªå€‹ LLM
USE_LLM = "groq"  # groq (æ¨è–¦)

# ==================== LLM è¨­å®š ====================

def get_llm():
    """æ ¹æ“šé…ç½®è¿”å›å°æ‡‰çš„ LLM"""

    if USE_LLM == "groq":
        from langchain_groq import ChatGroq

        # å„ªå…ˆå¾ç’°å¢ƒè®Šæ•¸è®€å–ï¼Œå¤±æ•—å‰‡å˜—è©¦ streamlit secrets
        api_key = os.getenv("GROQ_API_KEY")
        if not api_key:
            try:
                api_key = st.secrets["GROQ_API_KEY"]
            except Exception:
                api_key = None

        llm = ChatGroq(
            model="llama-3.3-70b-versatile",
            groq_api_key=api_key,
            temperature=0.7,
            max_tokens=512
        )
        return llm

# ==================== å¿«å–å‡½æ•¸ ====================

@st.cache_resource
def load_vectordb():
    """è¼‰å…¥å‘é‡è³‡æ–™åº«ï¼ˆåªè¼‰å…¥ä¸€æ¬¡ï¼‰"""
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

    vectordb = FAISS.load_local(
        "vectordb/faiss_index",
        embeddings,
        allow_dangerous_deserialization=True  # å®‰å…¨ï¼šæˆ‘å€‘è‡ªå·±å»ºç«‹çš„è³‡æ–™åº«
    )

    return vectordb

@st.cache_resource
def create_qa_chain(_vectordb):
    """å»ºç«‹å•ç­”éˆ"""

    template = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ›¸ç±æ¨è–¦åŠ©æ‰‹ã€‚æ ¹æ“šä»¥ä¸‹æ›¸ç±è³‡è¨Šå›ç­”å•é¡Œã€‚

ç›¸é—œæ›¸ç±è³‡è¨Šï¼š
{context}

å•é¡Œï¼š{question}

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸¦ä¸”ï¼š
1. æ¨è–¦ 2-3 æœ¬æœ€ç›¸é—œçš„æ›¸ç±
2. èªªæ˜æ¨è–¦ç†ç”±
3. æä¾›æ›¸åã€ä½œè€…å’Œç°¡çŸ­ä»‹ç´¹

å›ç­”ï¼š"""

    PROMPT = PromptTemplate(
        template=template,
        input_variables=["context", "question"]
    )

    llm = get_llm()

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=_vectordb.as_retriever(search_kwargs={"k": 10}),  # å¢åŠ åˆ° 10 æœ¬
        return_source_documents=True,
        chain_type_kwargs={"prompt": PROMPT}
    )

    return qa_chain

# ==================== Streamlit UI ====================

def main():
    st.set_page_config(
        page_title="ğŸ“š AI æ›¸ç±æ¨è–¦åŠ©æ‰‹",
        page_icon="ğŸ“š",
        layout="wide"
    )

    # æ¨™é¡Œ
    st.title("ğŸ“š AI æ›¸ç±æ¨è–¦åŠ©æ‰‹")
    st.markdown("åŸºæ–¼ Google Books è³‡æ–™ï¼Œä½¿ç”¨ RAG æŠ€è¡“æ¨è–¦å¥½æ›¸ | ğŸ†“ å®Œå…¨å…è²»")

    # é¡¯ç¤ºä½¿ç”¨çš„æŠ€è¡“
    st.caption(f"ğŸ’¡ ä½¿ç”¨æŠ€è¡“ï¼šFAISS + {USE_LLM.upper()} | æœ¬åœ° Embeddings")

    # è¼‰å…¥è³‡æº
    try:
        with st.spinner("è¼‰å…¥æ›¸ç±è³‡æ–™åº«..."):
            vectordb = load_vectordb()
            qa_chain = create_qa_chain(vectordb)
        st.success("âœ… è³‡æ–™åº«è¼‰å…¥å®Œæˆï¼")
    except Exception as e:
        st.error(f"âŒ è¼‰å…¥å¤±æ•—ï¼š{e}")
        st.info("è«‹ç¢ºèªï¼š\n1. å·²åŸ·è¡Œ build_vectordb.py\n2. API Key å·²è¨­å®š")
        return

    # å´é‚Šæ¬„
    with st.sidebar:
        st.header("ğŸ’¡ ä½¿ç”¨èªªæ˜")
        st.markdown("""
        è¼¸å…¥æ‚¨çš„å•é¡Œï¼ŒAI æœƒæ¨è–¦ç›¸é—œæ›¸ç±

        **ç¯„ä¾‹å•é¡Œï¼š**
        - æ¨è–¦ç§‘å¹»å°èªª
        - æœ‰ä»€éº¼å•†æ¥­æ›¸ç±ï¼Ÿ
        - é©åˆåˆå­¸è€…çš„å¿ƒç†å­¸æ›¸
        - æ¨è–¦ç¶“å…¸æ–‡å­¸ä½œå“
        """)

        st.divider()

        st.header("âš™ï¸ ç³»çµ±è³‡è¨Š")
        st.write(f"**LLM**ï¼š{USE_LLM.upper()}")
        if USE_LLM == "groq":
            st.write(f"**æ¨¡å‹**ï¼šllama-3.3-70b-versatile")

        st.write(f"**å‘é‡è³‡æ–™åº«**ï¼šFAISS v1.7.4")
        st.write(f"**Embedding æ¨¡å‹**ï¼š")
        st.write(f"- all-MiniLM-L6-v2")
        st.write(f"- sentence-transformers v2.2.2")
        st.write(f"- æœ¬åœ°é‹è¡Œ (CPU)")

        # é¡¯ç¤ºçµ±è¨ˆ
        if vectordb:
            st.metric("è³‡æ–™åº«æ–‡æª”æ•¸", vectordb.index.ntotal)

    # ä¸»è¦å€åŸŸ
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("ğŸ” æå‡ºå•é¡Œ")
        question = st.text_input(
            "è«‹è¼¸å…¥æ‚¨çš„å•é¡Œï¼š",
            placeholder="ä¾‹å¦‚ï¼šæ¨è–¦é©åˆæ–°æ‰‹çš„ç§‘å¹»å°èªª",
            label_visibility="collapsed"
        )

    with col2:
        st.write("")  # ç©ºç™½å°é½Š
        submit = st.button("ğŸš€ ç²å–æ¨è–¦", type="primary", use_container_width=True)

    # ç¯„ä¾‹å•é¡ŒæŒ‰éˆ•
    st.markdown("**å¿«é€Ÿç¯„ä¾‹ï¼š**")
    col1, col2, col3, col4 = st.columns(4)

    example_questions = {
        "ç§‘å¹»å°èªª": "æ¨è–¦ç¶“å…¸ç§‘å¹»å°èªª",
        "å•†æ¥­ç†è²¡": "æœ‰ä»€éº¼å•†æ¥­æˆ–ç†è²¡æ›¸ï¼Ÿ",
        "å¿ƒç†å­¸": "æ¨è–¦å¿ƒç†å­¸ç›¸é—œæ›¸ç±",
        "æ­·å²": "æœ‰ä»€éº¼æ­·å²é¡çš„å¥½æ›¸ï¼Ÿ"
    }

    for col, (label, q) in zip([col1, col2, col3, col4], example_questions.items()):
        with col:
            if st.button(label, use_container_width=True):
                question = q
                submit = True

    # è™•ç†å•ç­”
    if submit and question:
        with st.spinner("ğŸ¤” æ€è€ƒä¸­..."):
            try:
                result = qa_chain({"query": question})

                # é¡¯ç¤ºç­”æ¡ˆ
                st.markdown("### ğŸ’¬ æ¨è–¦çµæœ")
                st.write(result['result'])

                # é¡¯ç¤ºåƒè€ƒæ›¸ç±
                st.markdown("### ğŸ“š åƒè€ƒæ›¸ç±")

                for i, doc in enumerate(result['source_documents'][:6], 1):  # é¡¯ç¤ºå‰6æœ¬
                    with st.expander(f"ğŸ“– æ›¸ç± {i}ï¼š{doc.metadata.get('title', 'æœªçŸ¥')}"):
                        col_a, col_b = st.columns([1, 3])

                        with col_a:
                            if doc.metadata.get('thumbnail'):
                                st.image(doc.metadata['thumbnail'], width=120)

                        with col_b:
                            st.write(f"**ä½œè€…**ï¼š{doc.metadata.get('authors', 'æœªçŸ¥')}")
                            st.write(f"**é¡åˆ¥**ï¼š{doc.metadata.get('categories', 'æœªçŸ¥')}")
                            if doc.metadata.get('preview_link'):
                                st.markdown(f"[ğŸ“± é è¦½é€£çµ]({doc.metadata['preview_link']})")

            except Exception as e:
                st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                st.info("è«‹æª¢æŸ¥ API Key æ˜¯å¦æ­£ç¢ºè¨­å®š")

    elif submit and not question:
        st.warning("âš ï¸ è«‹è¼¸å…¥å•é¡Œï¼")

if __name__ == "__main__":
    main()
