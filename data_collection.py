"""
Google Books è³‡æ–™æ”¶é›†è…³æœ¬
åŠŸèƒ½ï¼šå¾ Google Books API æ”¶é›†æ›¸ç±è³‡æ–™
"""

import requests
import json
import time
from pathlib import Path

def search_books(query, max_results=40, language='zh-TW'):
    """
    å¾ Google Books API æœå°‹æ›¸ç±

    Args:
        query: æœå°‹é—œéµå­—
        max_results: æœ€å¤šçµæœæ•¸
        language: èªè¨€é™åˆ¶

    Returns:
        æ›¸ç±åˆ—è¡¨
    """
    all_books = []

    for start_index in range(0, max_results, 40):
        url = "https://www.googleapis.com/books/v1/volumes"
        params = {
            'q': query,
            'langRestrict': language,
            'maxResults': min(40, max_results - start_index),
            'startIndex': start_index,
            'printType': 'books'
        }

        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            all_books.extend(data.get('items', []))
            print(f"å·²æ”¶é›† {len(all_books)} æœ¬æ›¸...")
            time.sleep(1)  # é¿å… rate limit
        except Exception as e:
            print(f"éŒ¯èª¤ï¼š{e}")
            continue

    return all_books

def extract_book_info(book):
    """æå–æ›¸ç±é‡è¦è³‡è¨Š"""
    volume_info = book.get('volumeInfo', {})

    return {
        'id': book.get('id'),
        'title': volume_info.get('title', 'ç„¡æ¨™é¡Œ'),
        'authors': volume_info.get('authors', ['æœªçŸ¥ä½œè€…']),
        'publisher': volume_info.get('publisher', 'æœªçŸ¥å‡ºç‰ˆç¤¾'),
        'published_date': volume_info.get('publishedDate', 'æœªçŸ¥'),
        'description': volume_info.get('description', 'ç„¡æè¿°'),
        'categories': volume_info.get('categories', ['æœªåˆ†é¡']),
        'page_count': volume_info.get('pageCount', 0),
        'language': volume_info.get('language', 'zh'),
        'preview_link': volume_info.get('previewLink', ''),
        'thumbnail': volume_info.get('imageLinks', {}).get('thumbnail', ''),
    }

def collect_books_data(categories=None, books_per_category=40):
    """
    æ”¶é›†å¤šå€‹é¡åˆ¥çš„æ›¸ç±

    Args:
        categories: é¡åˆ¥åˆ—è¡¨
        books_per_category: æ¯å€‹é¡åˆ¥æ”¶é›†æ•¸é‡
    """
    if categories is None:
        categories = [
            'å°èªª',
            'ç§‘å¹»',
            'æ¨ç†',
            'æ„›æƒ…',
            'æ­·å²',
            'ç§‘æ™®',
            'å•†æ¥­',
            'è‡ªæˆ‘æˆé•·',
            'å“²å­¸',
            'å¿ƒç†å­¸',
            'è—è¡“',
            'éŸ³æ¨‚',
            'æ—…éŠ',
            'æ–™ç†',
            'é‹å‹•',
            'ç§‘æŠ€',
            'é†«å­¸',
            'æ•™è‚²', 
            'æŠ•è³‡',
            'è‚¡ç¥¨'
            ]

    all_books = []

    print(f"ğŸ“š é–‹å§‹æ”¶é›†æ›¸ç±è³‡æ–™...")
    print(f"é¡åˆ¥æ•¸é‡ï¼š{len(categories)}")
    print(f"æ¯é¡åˆ¥ï¼š{books_per_category} æœ¬")
    print("-" * 50)

    for i, category in enumerate(categories, 1):
        print(f"\n[{i}/{len(categories)}] æ”¶é›†ã€Œ{category}ã€é¡åˆ¥...")
        books = search_books(category, max_results=books_per_category)
        processed_books = [extract_book_info(book) for book in books]
        all_books.extend(processed_books)
        time.sleep(1)

    # å»é‡ï¼ˆæ ¹æ“š IDï¼‰
    unique_books = {book['id']: book for book in all_books}.values()
    unique_books = list(unique_books)

    # å„²å­˜è³‡æ–™
    Path('data').mkdir(exist_ok=True)
    output_file = 'data/books_raw.json'

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(unique_books, f, ensure_ascii=False, indent=2)

    print("\n" + "=" * 50)
    print(f"âœ… æ”¶é›†å®Œæˆï¼")
    print(f"ğŸ“Š ç¸½å…±æ”¶é›†ï¼š{len(unique_books)} æœ¬æ›¸ç±")
    print(f"ğŸ’¾ å„²å­˜ä½ç½®ï¼š{output_file}")
    print("=" * 50)

    return unique_books

if __name__ == "__main__":
    books = collect_books_data()
